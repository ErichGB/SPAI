{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementación centralizada de un algoritmo de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def readFile(filename):\n",
    "    return np.loadtxt(filename, delimiter=',')\n",
    "\n",
    "def _calculate_mean(numpy_Xy):\n",
    "    # Calcula la media de cada columna (axis=0) desde x0 a x10, \n",
    "    # Se excluye del cálculo la etiqueta (columna 11).\n",
    "    return np.mean(numpy_Xy[:, :-1], axis=0)\n",
    "\n",
    "def _calculate_desvest(numpy_Xy):\n",
    "    return np.std(numpy_Xy[:, :-1], axis=0)\n",
    "\n",
    "def normalize(numpy_Xy):\n",
    "    mean = _calculate_mean(numpy_Xy)\n",
    "    desvest = _calculate_desvest(numpy_Xy)\n",
    "    # La operación afecta sólo a los 11 primeros elemento\n",
    "    # No normaliza las etiquetas.\n",
    "    numpy_Xy[:, :-1] = (numpy_Xy[:, :-1] - mean) / desvest\n",
    "    return numpy_Xy\n",
    "\n",
    "def _model(W,b,numpy_Xy):\n",
    "    # Son los cálculos del modelo lineal, f(xi) = sumatorio X*W + b \n",
    "    return numpy_Xy[:, :-1] @ W + b\n",
    "\n",
    "def _sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def _cost_function_J(y, y_pred):\n",
    "    m = y.shape[0]\n",
    "    return -np.sum(y * np.log(y_pred) + (1 - y) * np.log(1 - y_pred)) / m\n",
    "\n",
    "def _convert_to_y_pred(value, threshold):\n",
    "    return np.where(value > threshold, 1, 0)\n",
    "\n",
    "def predict(W,b,numpy_Xy):\n",
    "    THRESHOLD = 0.5\n",
    "    z = _model(W,b,numpy_Xy)\n",
    "    y_hat = _sigmoid(z)\n",
    "    y_pred = _convert_to_y_pred(y_hat, THRESHOLD)\n",
    "    return y_pred\n",
    "\n",
    "def accuracy(W, b, numpy_Xy):\n",
    "    y = numpy_Xy[:,-1] # Etiquetas\n",
    "    m = numpy_Xy.shape[0]\n",
    "    y_pred = predict(W,b,numpy_Xy)\n",
    "    accuracy = np.sum(y == y_pred) / m\n",
    "    return accuracy\n",
    "\n",
    "def train(numpy_Xy, iterations, learning_rate):\n",
    "    m = numpy_Xy.shape[0]\n",
    "    W = 2 * np.random.rand(11) - 1\n",
    "    b = 2 * np.random.rand(1) - 1\n",
    "    data = numpy_Xy[:, :-1] # Datos\n",
    "    y = numpy_Xy[:,-1] # Etiquetas\n",
    "\n",
    "    for it in range(iterations):\n",
    "        z = _model(W,b,numpy_Xy)\n",
    "        y_hat = _sigmoid(z)\n",
    "        \n",
    "        dW = (data.T @ (y_hat - y)) / m\n",
    "        db = np.sum((y_hat - y)) / m\n",
    "        \n",
    "        W = W - learning_rate * dW\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        cost = _cost_function_J(y, y_hat)\n",
    "        print('Cost = ', cost)\n",
    "    \n",
    "    return W,b\n",
    "\n",
    "\n",
    "#FILE_NAME = '../../0-SPAI/1-datos/botnet_tot_syn_l.csv'\n",
    "FILE_NAME = 'botnet_sample.csv'\n",
    "LEARNING_RATE = 1.5\n",
    "N_ITER = 10\n",
    "\n",
    "# read data\n",
    "data_raw = readFile(FILE_NAME)\n",
    "\n",
    "# standarize\n",
    "normal_data = normalize(data_raw)\n",
    "\n",
    "# train\n",
    "ws = train(normal_data, N_ITER, LEARNING_RATE)\n",
    "\n",
    "W,b = ws\n",
    "acc = accuracy(W, b, normal_data)\n",
    "print('Accuracy = ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
