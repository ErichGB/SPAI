{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78a21aa9",
   "metadata": {},
   "source": [
    "**Integrantes: Erich Gonzalez, Daniel Gutierrez San José y Georgelys Marcano**\n",
    "\n",
    "Enunciado: \n",
    "\n",
    "    - Calcular mediante paralelizacion con Spark la media y varianza del dataset data_ok.csv utilizando exclusivamente funciones basicas map/reduce (textFile, reduce, reduceByKey, map, flatmap, filter, count).\n",
    "\n",
    "    - Calcular inicialmente para una sola columna y mas tarde para todas las columnas del dataset.\n",
    "\n",
    "    - Verificar que la solucion propuesta es correcta con las funciones rdd.mean() y rdd.stdev().\n",
    "\n",
    "Se deben realizar 3 versiones:\n",
    "\n",
    "    a1: Calcula la media y varianza para la columna 4\n",
    "\n",
    "    a2: utilizando las operaciones de vectorizacion de python y arrays de numpy, utilizar la misma estructura de codigo de la version 1 para calcular las medias y varianzas de todas las columnas\n",
    "\n",
    "    a3: Transforma cada celda del dataset en un elemento (j,v), donde \"j\" es la columna de la celda y \"v\" es el valor de la celda del rdd. Resuelve el problema con esta nueva estructura del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cde55d",
   "metadata": {},
   "source": [
    "### Versión a1: Calcula la media y varianza para la columna 4\n",
    "\n",
    "Para calcular la media y la varianza de los datos correspondientes a la columna 2, se hizo uso de las siguientes fórmulas:\n",
    "    varianza=(∑𝑥2𝑖𝑛)−(∑𝑥𝑖𝑛)2, lo que es equivalente a:\n",
    "                                    1𝑛∑𝑖=1𝑛(𝑥𝑖−𝜇)2\n",
    "    La media aritmética:\n",
    "                                    1𝑛∑𝑖=1𝑛(𝑥𝑖)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2991e681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf6f063",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[*]\",\"data_okCSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89d19009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La media de los valores de la columna2 son: 8544.5638\n",
      "La varianza es:  3168373338.3683057\n",
      "La desviación estandar es: 56288.3055204925\n"
     ]
    }
   ],
   "source": [
    "path = \"./data_ok.csv\"\n",
    "\n",
    "rdd = sc.textFile(path)\n",
    "\n",
    "# Se divide en rows eñ dataset\n",
    "pares = rdd.map(lambda x: float(x.split()[1]))\n",
    "\n",
    "#Se obtiene la suma de los valores de la columna2 para la media\n",
    "suma_columna2 = pares.reduce(lambda x,y : x+y)\n",
    "\n",
    "#Se obtiene el total de elementos con count\n",
    "total_columna2 = pares.count()\n",
    "\n",
    "#media de los datos de la columna2\n",
    "media = suma_columna2/total_columna2 \n",
    "print(\"La media de los valores de la columna2 son:\", media)\n",
    "\n",
    "#se obtiene la diferencia de cada elemento menos la media\n",
    "dif_cuadrados = pares.map(lambda x: float(x - media)**2)\n",
    "\n",
    "#Se suma los resultados obtenidos del map anterior\n",
    "sum_dif_cuadrados = dif_cuadrados.reduce(lambda x,y: x+y)\n",
    "\n",
    "#Se calcula la varianza\n",
    "varianza = sum_dif_cuadrados/total_columna2\n",
    "print(\"La varianza es: \", varianza)\n",
    "\n",
    "#Se calcula la desviación estandar\n",
    "desv = varianza**(1/2)\n",
    "print(\"La desviación estándar es:\" , desv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
