{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b481ed29",
   "metadata": {},
   "source": [
    "**Integrantes: Erich Gonzalez, Daniel Gutierrez San José y Georgelys Marcano**\n",
    "\n",
    "Enunciado: \n",
    "\n",
    "    - Calcular mediante paralelización con Spark la media y varianza del dataset data_ok.csv utilizando exclusivamente funciones básicas map/reduce (textFile, reduce, reduceByKey, map, flatmap, filter, count).\n",
    "\n",
    "    - Calcular inicialmente para una sola columna y más tarde para todas las columnas del dataset.\n",
    "\n",
    "    - Verificar que la solución propuesta es correcta con las funciones rdd.mean() y rdd.stdev().\n",
    "\n",
    "Se deben realizar 3 versiones:\n",
    "\n",
    "    a1: Calcula la media y varianza para la columna 4\n",
    "\n",
    "    a2: Utilizando las operaciones de vectorización de python y arrays de numpy, utilizar la misma estructura de código de la version 1 para calcular las medias y varianzas de todas las columnas\n",
    "\n",
    "    a3: Transforma cada celda del dataset en un elemento (j,v), donde \"j\" es la columna de la celda y \"v\" es el valor de la celda del rdd. Resuelve el problema con esta nueva estructura del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08526f6b",
   "metadata": {},
   "source": [
    "### Versión a3: Transforma cada celda del dataset en un elemento (j,v), donde \"j\" es la columna de la celda y \"v\" es el valor de la celda del rdd. Resuelve el problema con esta nueva estructura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060a450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local[*]\", \"v.a3-media-varianza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ce9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ruta del csv\n",
    "path = \"./data_ok.csv\" \n",
    "\n",
    "#se ingresa la ruta en file del sc (rdd)\n",
    "rdd = sc.textFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ebc43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se obtiene el rdd1, transformando el dataset en un array de arrays, donde cada valor es un row\n",
    "rdd1 = rdd.map(lambda linea:linea.split())\n",
    "\n",
    "# transformar a float (rdd2)\n",
    "rdd2 = rdd1.map(lambda row: [float(celda) for celda in row])\n",
    "\n",
    "#Se realiza un map para obtener una matriz con valores (j,v)\n",
    "rdd3 = rdd2.map(lambda row:[(columna,valor) for columna,valor in enumerate(row)])\n",
    "\n",
    "#Se realiza un reduce para obtener la suma de todos los valores de la matriz\n",
    "sum_elements = rdd3.reduce(lambda row1,row2:[(indice,item[1]+row2[indice][1]) for indice,item in enumerate(row1)])\n",
    "\n",
    "#Se totaliza la cantidad de elementos, para obtener un array de medias\n",
    "total_item_rows = rdd2.count()\n",
    "means_col = []\n",
    "for index,tupla in enumerate(sum_elements):\n",
    "    means = tupla[1] / total_item_rows\n",
    "    means_col.append(means)\n",
    "#print(\"Media de cada columna:\", means_col[:3])\n",
    "\n",
    "# Calcular la varianza\n",
    "sum_dif_quarts = tuplas.map(lambda row: [(index, (valor[1] - means_col[index])**2) for index, valor in enumerate(row)])\n",
    "\n",
    "# Reducir para sumar las diferencias cuadradas\n",
    "sum_variance = sum_dif_quarts.reduce(lambda row1, row2: [(index, item[1] + row2[index][1]) for index, item in enumerate(row1)])\n",
    "\n",
    "# Calcular la varianza dividiendo entre el total de filas\n",
    "variance_col = [tupla[1] / total_item_rows for tupla in sum_variance]\n",
    "#print(variance_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
