{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b481ed29",
   "metadata": {},
   "source": [
    "**Integrantes: Erich Gonzalez, Daniel Gutierrez San José y Georgelys Marcano\n",
    "\n",
    "Enunciado: \n",
    "\n",
    "    - Calcular mediante paralelizacion con Spark la media y varianza del dataset data_ok.csv utilizando exclusivamente funciones basicas map/reduce (textFile, reduce, reduceByKey, map, flatmap, filter, count).\n",
    "\n",
    "    - Calcular inicialmente para una sola columna y mas tarde para todas las columnas del dataset.\n",
    "\n",
    "    - Verificar que la solucion propuesta es correcta con las funciones rdd.mean() y rdd.stdev().\n",
    "\n",
    "Se deben realizar 3 versiones:\n",
    "\n",
    "    a1: Calcula la media y varianza para la columna 2\n",
    "\n",
    "    a2: utilizando las operaciones de vectorizacion de python y arrays de numpy, utilizar la misma estructura de codigo de la version 1 para calcular las medias y varianzas de todas las columnas\n",
    "\n",
    "    a3: Transforma cada celda del dataset en un elemento (j,v), donde \"j\" es la columna de la celda y \"v\" es el valor de la celda del rdd. Resuelve el problema con esta nueva estructura del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08526f6b",
   "metadata": {},
   "source": [
    "### Versión a3: Transforma cada celda del dataset en un elemento (j,v), donde \"j\" es la columna de la celda y \"v\" es el valor de la celda del rdd. Resuelve el problema con esta nueva estructura del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "060a450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark import SparkContext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daeb590a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/25 20:51:11 WARN Utils: Your hostname, DESKTOP-KLPDI5O resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/09/25 20:51:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/georgelysm/miniconda3/envs/py37/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/25 20:51:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext(\"local[*]\", \"version3a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4ce9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path =  \"./data_ok.csv\"\n",
    "file = sc.textFile(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68ebc43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[401818.16628544027, 3168373338.3683057, 2959605.6432505627, 5883755024032.205, 0.0, 2.3010223599999864, 0.0, 313332.59728123934, 19828.36648764016, 345513253204.2377, 6514263.902446111, 0.03228335999999504, 0.05090556000000112, 3.9563996399999914, 14631.804300159674, 19686496.994590227, 103958.43979824062, 12358118332394.264, 435068936.0129385, 0.0, 114088.27606048658, 151781717098.3398, 3110.345729247053, 19567004.17901126, 0.0, 105249.50629016865, 11237.074611699474, 19550727.745639034, 0.0, 215925.38426967297, 14448.852004224205, 19659327.47487623, 596.8763070399867, 202491.0921141331, 176553635.66167575, 590364421.4027784, 43583.33676315991, 40518057.64093468, 3760978.8000936317, 19624991.613284435, 1923635.5490620334, 1689189.9964354113, 401750.96461244015, 3174031454.5406246, 2959811.9491644404, 5884337014379.24, 0.0, 2.3098521600000868, 0.0, 310335.4895564397, 20014.45445755969, 345325149316.8787, 6514263.902446111, 0.03228335999999504, 0.04515323999999891, 3.599737439999948, 1008.3260921599971, 19669697.390177786, 105359.28649083897, 12399973857981.857, 424424770.16485584, 0.0, 113911.20452837195, 151809487377.74854, 2869.0495244776203, 19560250.921963997, 0.0, 104037.49503196981, 11070.200210098645, 19544840.104067333, 0.0, 214401.02888595642, 12239.167531509715, 19647194.62981504, 623.2420709999916, 199700.55921450557, 176856177.94215602, 590571650.0401825, 43613.7685932395, 40589060.616536885, 3758682.7710593734, 19619172.390930824, 1922206.4497950077, 1688549.4526252467, 401685.4170892401, 3178174429.3841233, 2960015.626820759, 5884864588784.286, 0.0, 2.32749999999992, 0.0, 308245.91293595906, 20081.538283160124, 345125573087.26715, 6514263.902446111, 0.03228335999999504, 0.04515323999999891, 3.599737439999948, 1008.3260921599971, 19626333.313879214, 107920.94155803983, 12399925642387.176, 424857073.28193396, 0.0, 113912.74714482974, 151813276235.68878, 3222.3967242800168, 19924766.992032047, 0.0, 116913.97342227455, 12167.537305429385, 19907274.222736035, 0.0, 238023.2177429371, 11897.499542177913, 19639897.401612516, 596.3006735600056, 197483.74575918683, 177125503.9952667, 590660710.9182191, 43573.900655999685, 40645248.632894345, 4154162.23082848, 19983930.59718044, 2333453.8135999944, 1687414.2018320968, 401623.47488284006, 3184068337.4555902, 2960204.4312870377, 5885440210916.09, 0.0, 2.32749999999992, 0.0, 305683.2263020405, 20052.0025017596, 344882319157.6697, 6514263.902446111, 0.03228335999999504, 0.04515323999999891, 3.599737439999948, 1008.3260921599971, 19581698.139801342, 105257.7524440002, 12399800568847.506, 424857073.28193396, 0.0, 114068.81133984415, 151842501349.58, 3795.642535301657, 19972641.289239552, 0.0, 119947.23579548075, 11870.16230021874, 19945348.824247587, 0.0, 238688.13700569802, 16932.796030991376, 20004031.795615837, 564.8062877500012, 226291.339360886, 177231854.42917913, 590721856.9716674, 43519.71121084023, 40672868.143737845, 4176128.2969749565, 20031808.553314295, 2361237.0645750156, 1692761.7380481912, 401572.9392396404, 3189603909.434815, 2960369.68223836, 5885938022413.459, 0.0, 2.32749999999992, 0.0, 305163.3500198418, 20057.81816623984, 344693104594.8094, 6514263.902446111, 0.03228335999999504, 0.04515323999999891, 3.599737439999948, 1008.3260921599971, 19527954.350401666, 107447.93568384004, 12399740431332.062, 425072247.54278713, 0.0, 114292.21310716867, 151894923790.8821, 9560.58844900609, 21330722.778348558, 0.0, 200326.38092967667, 15151.721039831144, 20193156.59520815, 0.0, 258081.99827338697, 37120.32927669178, 21133016.81082881, 131.1962523899973, 358669.35209705523, 177438402.45366213, 590900365.9273086, 43445.0653022396, 40775679.138265714, 4128796.791232701, 21389788.4512459, 2175344.8689694456, 1956630.6238030815, 0.0]\n"
     ]
    }
   ],
   "source": [
    "rdd = file.map(lambda linea:linea.split())\n",
    "# transformar a float\n",
    "datasetfloat = rdd.map(lambda row: [float(celda) for celda in row])\n",
    "tuplas = datasetfloat.map(lambda row:[(columna,valor) for columna,valor in enumerate(row)])\n",
    "#tuplas.take(2)\n",
    "suma = tuplas.reduce(lambda row1,row2:[(indice,item[1]+row2[indice][1]) for indice,item in enumerate(row1)])\n",
    "#print(suma)\n",
    "total_item_rows = datasetfloat.count()\n",
    "media_col = []\n",
    "for index,tupla in enumerate(suma):\n",
    "    media = tupla[1] / total_item_rows\n",
    "    media_col.append(media)\n",
    "#print(\"Media de cada columna:\", media_col)\n",
    "# Calcular la varianza\n",
    "suma_diferencias_cuadradas = tuplas.map(lambda row: [(indice, (valor[1] - media_col[indice])**2) for indice, valor in enumerate(row)])\n",
    "# Reducir para sumar las diferencias cuadradas\n",
    "suma_varianza = suma_diferencias_cuadradas.reduce(lambda row1, row2: [(indice, item[1] + row2[indice][1]) for indice, item in enumerate(row1)])\n",
    "# Calcular la varianza dividiendo entre el total de filas\n",
    "varianza_col = [tupla[1] / total_item_rows for tupla in suma_varianza]\n",
    "print(varianza_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
